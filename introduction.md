# C语言内存模型
## 1，什么是“栈溢出”？
类似水满则溢吧，栈区的容量是有限的（哪怕加上了共享数据区），不停使用栈的空间总会到空间耗尽的时候，栈空间用完后再占用栈空间就会溢出，然后轻则程序崩溃，重则数据损坏，栈就爆了。
>举个栗子
```cpp
void a(int i)
{
    if (i)
    {
        printf("%d",i);
        a(i+1);
    }
}
```
以上程序不停调用自己本身（应该是一种递归算法）就会出现栈溢出。

---

## 2，堆区和栈区的区别是什么？
### a.储存的内容不同
栈————函数，函数形参，函数的局部变量等，返回后自动释放空间
堆————程序动态开辟的空间（链表，树，图等动态分布的数据结构），需要手动释放（free，delete等）
### b.内存增长方式不同
栈的内存向下（低地址）增长，堆的内存向上（高地址）增长。

## 3，程序运行过程中，内存模型当中的哪些区是只读的，哪些区是可读写的？
常量区（.rodata）和代码区（.text）是只读的，栈（stack），堆（heap），全局区（.bss,.data）是可读写的
>ps：好像有些没有分这么细，我就按细的写了（
## 4，如何使用malloc()、free()函数，它们针对的哪一个区进行操作？
针对堆（heap）区操作
## 5，为什么要对程序使用的内存进行管理？
### 1，内存分区管理可以减少内存碎片
>碎片空间指细小但无法利用的空间，如假设两个需要动态分配内存的int变量各占4字节，而两个变量在内存中动态分配出的存储的空间间隔了1个字节，那么这一个字节就无法有效利用。

碎片空间的产生通常位于动态分配区域，而正因划分了动态与静态区域让分配内存的时候不必在所有的内存空间中随机选取地方，而是只有需要动态分配内存的数据动态分配，静态分配区就减少了碎片空间的产生，从而降低了内存空间的浪费，提高了效率
### 2，提高程序整体的效率与速度
如**栈**：将函数主体，形参，局部变量等被经常调用的东西放在栈中，不用零散的去访问内存，而且栈的特点也符合函数调用时的情况（先入后出）
其他的分区也类似，储存同一种数据类型，可以分别使用更高效的管理模式，访问的时候整体访问提高访问速度，提高整体的效率
### 3，让程序中内存分配更灵活
内存分区中存在data,bss，rodata的**静态分配**区，heap，stack，动态链接库的**动态分配区**，静态分配的空间固定，访问速度快，动态分配可以自由分配大小，且可以更改。两者结合起来使程序整体的内存分配更加自由灵活（不需要经常更改的变量可以放于静态分配的空间中，而如链表的节点这些需要动态增删的部分就用动态分配，而不必全都静态或全都动态，按各自的需求分配）
### 4，只读区的存在提高了程序的安全性
### 5，便于人理解（毕竟分了区嘛）
>可能不够全面qwq，仅是个人理解

>另外，网上似乎对内存模型没有一个比较统一的说法，堆，栈，共享数据区，代码区是比较统一的，而剩下的说法似乎不太统一，但内存模型应该是按照实际内存分配的情况展示出来的，应该是有一个统一的标准吧（？对这里有点疑问（也有可能是我没查到位）

---

# 内存模型的应用
**constValue**：为const声明的全局固定常量（整形的），储存在内存模型中的只读数据段（.rodata）
**constString**：指向“变量”（就是指针指向的东西可以变）的常量指针，但不能通过指针修改，也储存在常量区
>ps:这个是问的程算的老师得到的解答，好像还有int* const这种，但意义不一样，非常绕（（bushi
**globalVar**：全局变量（整型）且已经初始化，储存在.data段（属于全局数据区）
**staticVar**：静态全局变量
**localVar**：局部静态变量，虽然是局部，但储存在只读数据段（.rodata）中
**ptr**：局部指针变量，储存在栈中
**localVarMain**：局部变量（整形），储存在栈中。

---
# 浅谈Cache
## 什么是冯诺伊曼体系结构？什么是现代计算机的组织结构？这两者的不同点在哪里？
**冯诺依曼体系结构**包括了**储存器**，**控制器**，**运算器**，**输入设备**，**输出设备**。（如图所示）![](微信图片_20241015195825.jpg)
>ps：输入端输入的代码会转化为机器语言再传入内存中（就是编译器做的工作）（吧？
>ps（半个心得体会？）：外部存储器（硬盘等）在日常使用的过程中访问的频率远低于内存，内存有点像一个大一点的缓存，但比缓存慢，比内存快。虽然现在有pcie4.0，但硬盘等的在主板上与cpu间的线路是远长与内存的（带宽就不知道了）。且内存有2x8>16的说法，相当于拓宽马路吧，让读写速度更快。
其中，较为特别的是存储器，这也是冯诺伊曼体系结构的核心（网上说的），存储器与控制器间用一条总线，即指令和数据是公用一条线路传输，这样不需要分别单独制作指令和数据的储存器，节约成本，而且编程更加简单（不需要分别考虑数据和指令的存放），但会比两者分开的结构慢（如哈佛结构）

**现代计算机的组织结构**：to be honest 我没找到一个类似冯诺依曼体系结构这样的名词（，所以我就就我了解说一下吧。首先主要的5个部分是不变的，但在运算器和控制器集成的cpu中加入了缓存，加速了数据的传输。还有将指令的储存和数据的储存分开的哈佛结构，这样指令和数据就可以分别用各自的总线，使cpu可以同时读取指令和数据，打破了冯诺依曼结构的瓶颈。还有在cpu中加入了专门的浮点数运算单元，分担运算器负担。
而且还有很多不是基于冯诺依曼结构的计算机，如并行计算机（好像是通过互联网络将多个节点连接起来，每个节点都可以独立进行运算，结构很复杂，我也没太搞清楚），量子计算机等

## 主存储器是如何工作的？
我理解的主储存器是指内存（不知道对不对）。内存也就是RAM，分为DRAM和SRAM两种，大多数用到的都是DRAM（应该）（如DDR4内存）。内存中的一个个电容单元排布成二维阵列，每个单元只能储存1bit的数据，而且需要通电使用，也就是说主板断电后其储存的信息将不会保留。假设计算机需要打开存放在硬盘中的黑神话悟空，在你双击后，游戏需要一定时间才能打开，而这段时间就是在将黑猴中的部分数据（通常是文件，如人物模型，场景模型，纹理等等）临时存放在内存中，之后就直接通过内存与cpu的通道来交换数据。再举个例子，链表节点通常需要动态创建，申请的空间通常是在内存中（也可能在缓存）。在运行过程中，cpu会从内存中获取内存地址，再执行完相关操作后返回内存地址与操作结果，对内存内容进行更改。以上就是我对主存储器工作的理解（（，如有错误请指正qwq

## 什么是Cache的局部性原理？它包括哪些方面的内容？
首先先说一下缓存存储的只是一部分内存中的数据，而且是需要被频繁调用的数据，而这些数据在内存中通常处于相邻的区域，而且刚刚被访问过的数据被再次访问的可能性也是很大的，这就是空间局部性和时间局部性。缓存在存储数据的时候会把数据周围的一块部分也预存入（不会很大），这样就把访问次数很高的数据放入缓存中，加快处理速度。
## Cache的运用为什么可以加快系统整体性能？
Cache在计算机的很多部件中都存在，都对性能有一定的提升，我都分别讲讲吧
### cpu
cpu内部集成了缓存，因为在内部所以与cpu的控制器，运算器连接的线路很短，传输速度很快。同时，cpu内部缓存采用了多级缓存，L1,L2,L3三级缓存，相当于优化算法吧，提升了读写的效率。
### gpu
与cpu同样，存在多级缓存，访问速度快于主存，因而多用来存放被访问频率很高的数据，减少对主存的访问次数（有点像局部性？）
### 固态
1，部分固态硬盘会单独设立缓存，缓存中可以存放文件的ftl表，不需要在固态主控或者占用部分存储空间放置，且这样可以更快读取到文件在内存中放置的位置
2，部分固态硬盘的缓存可以缓解写放大现象（把固态比作一本笔记本，每次写入的时候都会选一个页（固态中是类似的一串晶体管）进行写入，如果内容没占满这一页，那么剩下的空白就无法再利用了，而当所有页写完后，每页中都有浪费空间，这样只能将原来某页擦除然后再重新写满，而固态的读写总次数是有上线，这样就加速了固态的损耗），而缓存的使用可以先将单位页中的内容暂存在缓存中，等到够了一页的数据在写入，一次写满不浪费^_^
### 显示器（虽然对性能提升不是很关键）
用于存放即将播放的帧，还可以存放接受到来自内存中需要显示的数据或者其他，提高帧率，减少撕裂与延迟
>ps:可能不够全面，但缓存凭借访问快的优势就可以很大程度上提高性能了。